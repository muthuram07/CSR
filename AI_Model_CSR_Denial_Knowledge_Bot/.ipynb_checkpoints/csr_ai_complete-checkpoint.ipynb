{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete CSR AI Training & API Service\n",
    "\n",
    "This notebook contains everything you need:\n",
    "1. Upload your CSV datasets\n",
    "2. Train the conversational AI model \n",
    "3. Start the API service on port 5004\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (2.3.1)\n",
      "Requirement already satisfied: flask in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (3.1.1)\n",
      "Requirement already satisfied: flask-cors in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (6.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (2.3.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (1.7.1)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (8.1.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: blinker>=1.9.0 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from flask) (8.2.1)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from flask) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from flask) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\2389405\\appdata\\roaming\\python\\python313\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies (CSV-only)\n",
    "!pip install pandas flask flask-cors numpy scikit-learn ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Running in CSV-only mode (no ML libraries).\n",
      "üìÅ Upload your 3 CSV files (CSV-only mode):\n",
      "1. Denial reasons CSV:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197bf0413ca34bf7a1355f3b29ba56fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.csv', description='Denial CSV')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Member subscription CSV:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75661784d327448c96bbcc442866cc78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.csv', description='Member CSV')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Plan coverage CSV:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7444aa07a24e8b94942bfba98f4ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.csv', description='Plan CSV')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload CSV files and imports\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging, json, random, threading, time, re\n",
    "\n",
    "# ML Libraries removed ‚Äî CSV-only mode\n",
    "TRAINING_AVAILABLE = False\n",
    "print(\"‚úÖ Running in CSV-only mode (no ML libraries).\")\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Create datasets directory\n",
    "os.makedirs('datasets', exist_ok=True)\n",
    "\n",
    "print(\"üìÅ Upload your 3 CSV files (CSV-only mode):\")\n",
    "denial_upload = widgets.FileUpload(accept='.csv', description='Denial CSV')\n",
    "member_upload = widgets.FileUpload(accept='.csv', description='Member CSV') \n",
    "plan_upload = widgets.FileUpload(accept='.csv', description='Plan CSV')\n",
    "\n",
    "print(\"1. Denial reasons CSV:\")\n",
    "display(denial_upload)\n",
    "print(\"2. Member subscription CSV:\")\n",
    "display(member_upload)  \n",
    "print(\"3. Plan coverage CSV:\")\n",
    "display(plan_upload)\n",
    "\n",
    "# Global data variables\n",
    "denial_data = member_data = plan_data = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 415 denial codes loaded\n",
      "‚úÖ 10000 members loaded\n",
      "‚úÖ 100 plans loaded\n",
      "‚úÖ CSVs loaded. Skipping model training (CSV-only mode).\n"
     ]
    }
   ],
   "source": [
    "# CSV Loading with Encoding Support - NO HARDCODING!\n",
    "def load_csv_with_encoding(file_path):\n",
    "    \"\"\"Load CSV with multiple encoding attempts - NO FALLBACK HARDCODED DATA\"\"\"\n",
    "    encodings = ['utf-8', 'utf-8-sig', 'latin-1', 'cp1252', 'iso-8859-1']\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            logger.info(f\"üìÅ Trying to load {file_path} with {encoding} encoding...\")\n",
    "            try:\n",
    "                return pd.read_csv(file_path, encoding=encoding)\n",
    "            except:\n",
    "                return pd.read_csv(file_path, encoding=encoding, sep=',', quotechar='\"', skipinitialspace=True)\n",
    "        except UnicodeDecodeError:\n",
    "            logger.warning(f\"‚ö†Ô∏è  Failed with {encoding} encoding, trying next...\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"‚ö†Ô∏è  Failed parsing {file_path} with {encoding}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # NO HARDCODED DATA - Must use uploaded datasets only\n",
    "    raise Exception(f\"‚ùå Could not load {file_path} with any supported encoding. Please check your CSV file format.\")\n",
    "\n",
    "\n",
    "\n",
    "def process_uploads():\n",
    "    global denial_data, member_data, plan_data\n",
    "\n",
    "    try:\n",
    "        denial_data = pd.read_csv(\"datasets/denial_reason.csv\")\n",
    "        print(f\"‚úÖ {len(denial_data)} denial codes loaded\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è Missing: datasets/denial_reason.csv\")\n",
    "\n",
    "    try:\n",
    "        member_data = pd.read_csv(\"datasets/member_subscription.csv\")\n",
    "        print(f\"‚úÖ {len(member_data)} members loaded\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è Missing: datasets/member_subscription.csv\")\n",
    "\n",
    "    try:\n",
    "        plan_data = pd.read_csv(\"datasets/plan_coverage.csv\")\n",
    "        print(f\"‚úÖ {len(plan_data)} plans loaded\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è Missing: datasets/plan_coverage.csv\")\n",
    "\n",
    "    return all([denial_data is not None, member_data is not None, plan_data is not None])\n",
    " \n",
    "\n",
    "# Training Conversation Generation (EXACT same as Python files - NO HARDCODING)\n",
    "def generate_denial_conversations():\n",
    "    \"\"\"Generate conversations about denial codes from your data\"\"\"\n",
    "    conversations = []\n",
    "    \n",
    "    for _, row in denial_data.iterrows():\n",
    "        user_code = row['user_code']\n",
    "        denial_code = row['denial_code']\n",
    "        description = row['description']\n",
    "        action = row['suggested_action']\n",
    "        \n",
    "        # Generate various natural ways users might ask about this denial\n",
    "        questions = [\n",
    "            f\"What does denial code {denial_code} mean?\",\n",
    "            f\"Why was my claim rejected with code {denial_code}?\",\n",
    "            f\"Can you explain {user_code}{denial_code}?\",\n",
    "            f\"I got a denial with code {denial_code}, what should I do?\",\n",
    "            f\"What is the reason for denial code {denial_code}?\",\n",
    "            f\"Help me understand why code {denial_code} was used\",\n",
    "            f\"My claim shows {user_code} {denial_code}, what's wrong?\",\n",
    "            f\"Explain the denial code {user_code}{denial_code}\",\n",
    "            f\"What does code {denial_code} indicate?\",\n",
    "            f\"I received denial {denial_code}, what's the next step?\"\n",
    "        ]\n",
    "        \n",
    "        for question in questions:\n",
    "            conversation_text = f\"User: {question}\\nAssistant: Denial code {denial_code} ({user_code}) means: {description}\\n\\nRecommended action: {action}<|endoftext|>\"\n",
    "            conversations.append(conversation_text)\n",
    "    \n",
    "    return conversations\n",
    "\n",
    "def generate_plan_conversations():\n",
    "    \"\"\"Generate conversations from pure CSV data without hardcoded questions\"\"\"\n",
    "    conversations = []\n",
    "    \n",
    "    # Get member data to create realistic plan queries\n",
    "    for _, member in member_data.iterrows():\n",
    "        plan_info = plan_data[plan_data['plan_id'] == member['plan_id']]\n",
    "        if not plan_info.empty:\n",
    "            plan_row = plan_info.iloc[0]\n",
    "            \n",
    "            # Natural questions about plan coverage\n",
    "            questions = [\n",
    "                f\"Is dental covered for member {member['member_id']}?\",\n",
    "                f\"What's the copay for {member['member_name']}?\",\n",
    "                f\"Does {member['member_id']} have vision coverage?\",\n",
    "                f\"Tell me about {member['member_name']}'s plan\",\n",
    "                f\"What services are covered for member {member['member_id']}?\",\n",
    "                f\"What's the coverage for {member['member_name']}?\",\n",
    "                f\"Check {member['member_id']} plan benefits\",\n",
    "                f\"Show plan details for {member['member_name']}\",\n",
    "                f\"What does {member['member_id']}'s plan cover?\",\n",
    "                f\"Is emergency care covered for {member['member_name']}?\"\n",
    "            ]\n",
    "            \n",
    "            for question in questions:\n",
    "                # Provide raw data context - let AI model learn to interpret and answer\n",
    "                data_context = f\"\"\"Member: {member['member_name']} ({member['member_id']})\n",
    "Status: {member['status']}\n",
    "Plan ID: {member['plan_id']}\n",
    "Coverage Period: {member['effective_date']} to {member['end_date']}\n",
    "Coverage Type: {plan_row['coverage_type']}\n",
    "Covered Services: {plan_row['covered_services']}\n",
    "Copay: {plan_row['copay']}\n",
    "Notes: {plan_row['notes']}\"\"\"\n",
    "                \n",
    "                # Create direct conversation text format - AI learns from data context\n",
    "                conversation_text = f\"User: {question}\\nAssistant: {data_context}<|endoftext|>\"\n",
    "                conversations.append(conversation_text)\n",
    "    \n",
    "    return conversations\n",
    "\n",
    "def generate_member_conversations():\n",
    "    \"\"\"Generate conversations about member information\"\"\"\n",
    "    conversations = []\n",
    "    \n",
    "    for _, member in member_data.iterrows():\n",
    "        member_id = member['member_id']\n",
    "        name = member['member_name']\n",
    "        plan_id = member['plan_id']\n",
    "        status = member['status']\n",
    "        effective_date = member['effective_date']\n",
    "        end_date = member['end_date']\n",
    "        \n",
    "        # Find plan details for this member\n",
    "        plan_info = plan_data[plan_data['plan_id'] == plan_id]\n",
    "        plan_details = \"\"\n",
    "        if not plan_info.empty:\n",
    "            plan_row = plan_info.iloc[0]\n",
    "            plan_details = f\"Their {plan_row['coverage_type']} plan covers: {plan_row['covered_services']}\"\n",
    "        \n",
    "        questions = [\n",
    "            f\"Show me details for member {member_id}\",\n",
    "            f\"What plan is {name} on?\",\n",
    "            f\"Give me information about {member_id}\",\n",
    "            f\"Tell me about {name}\",\n",
    "            f\"What's {member_id} member status?\",\n",
    "            f\"When does {name}'s coverage end?\",\n",
    "            f\"Is member {member_id} active?\",\n",
    "            f\"Find {name} in the system\",\n",
    "            f\"Look up member {member_id}\",\n",
    "            f\"What coverage does {name} have?\"\n",
    "        ]\n",
    "        \n",
    "        for question in questions:\n",
    "            # Provide raw data context - let AI model learn to interpret and answer\n",
    "            data_context = f\"\"\"Member: {name} ({member_id})\n",
    "Status: {status}\n",
    "Plan ID: {plan_id}\n",
    "Coverage Period: {effective_date} to {end_date}\n",
    "Plan Details: {plan_details}\"\"\"\n",
    "            \n",
    "            # Create direct conversation text format - AI learns from data context\n",
    "            conversation_text = f\"User: {question}\\nAssistant: {data_context}<|endoftext|>\"\n",
    "            conversations.append(conversation_text)\n",
    "    \n",
    "    return conversations\n",
    "\n",
    "def generate_complex_conversations():\n",
    "    \"\"\"Generate complex multi-entity conversations\"\"\"\n",
    "    conversations = []\n",
    "    \n",
    "    # Complex queries combining member + plan + denial\n",
    "    for _, member in member_data.iterrows():\n",
    "        plan_info = plan_data[plan_data['plan_id'] == member['plan_id']]\n",
    "        if not plan_info.empty:\n",
    "            plan_row = plan_info.iloc[0]\n",
    "            \n",
    "            # Member + plan questions\n",
    "            questions = [\n",
    "                f\"What benefits does {member['member_name']} have?\",\n",
    "                f\"Is dental covered for member {member['member_id']}?\",\n",
    "                f\"What's {member['member_name']}'s copay for emergency?\",\n",
    "                f\"Does {member['member_id']} have vision coverage?\",\n",
    "                f\"Tell me about {member['member_name']}'s plan coverage\"\n",
    "            ]\n",
    "            \n",
    "            for question in questions:\n",
    "                # Provide raw data context - let AI model learn to interpret and answer\n",
    "                data_context = f\"\"\"Member: {member['member_name']} ({member['member_id']})\n",
    "Status: {member['status']}\n",
    "Plan ID: {member['plan_id']}\n",
    "Coverage Period: {member['effective_date']} to {member['end_date']}\n",
    "Coverage Type: {plan_row['coverage_type']}\n",
    "Covered Services: {plan_row['covered_services']}\n",
    "Copay: {plan_row['copay']}\n",
    "Notes: {plan_row['notes']}\"\"\"\n",
    "                \n",
    "                # Create direct conversation text format - AI learns from data context\n",
    "                conversation_text = f\"User: {question}\\nAssistant: {data_context}<|endoftext|>\"\n",
    "                conversations.append(conversation_text)\n",
    "    \n",
    "    return conversations\n",
    "\n",
    "def generate_training_conversations():\n",
    "    \"\"\"Generate natural conversation data from your CSV files\"\"\"\n",
    "    conversations = []\n",
    "    \n",
    "    # Generate denial code conversations\n",
    "    conversations.extend(generate_denial_conversations())\n",
    "    \n",
    "    # Generate plan coverage conversations\n",
    "    conversations.extend(generate_plan_conversations())\n",
    "    \n",
    "    # Generate member lookup conversations\n",
    "    conversations.extend(generate_member_conversations())\n",
    "    \n",
    "    # Generate mixed/complex conversations\n",
    "    conversations.extend(generate_complex_conversations())\n",
    "    \n",
    "    logger.info(f\"üéØ Generated {len(conversations)} training conversations\")\n",
    "    return conversations\n",
    "\n",
    "def train_conversational_model(model_name=None):\n",
    "    \"\"\"Model training removed. Running in CSV-only mode.\"\"\"\n",
    "    logger.info(\"üõë Training disabled ‚Äî CSV-only mode.\")\n",
    "    return None\n",
    "\n",
    "# Process uploads (CSV-only mode; training disabled)\n",
    "if process_uploads():\n",
    "    print(\"‚úÖ CSVs loaded. Skipping model training (CSV-only mode).\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Upload all 3 CSV files first, then re-run this cell\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Loaded CSV data: 415 denials, 10000 members, 100 plans\n",
      "INFO:__main__:‚úÖ Trained CSR Model Service initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting CSR CSV Lookup API on http://localhost:5004\n",
      "üì° Endpoints:\n",
      "   POST /query\n",
      "   GET  /health\n",
      "   GET  /train-status\n",
      "   GET  /available-data\n",
      "üéâ API service started! Keep this cell running.\n",
      "Your Spring Boot backend can connect to: http://localhost:5004\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5004\n",
      " * Running on http://192.168.1.113:5004\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API thread running (non-blocking).\n"
     ]
    }
   ],
   "source": [
    "# === Trained Model API (Notebook cell) ‚Äî same structure/behavior as trained_model_api.py ===\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import threading\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "# Resolve datasets absolute path\n",
    "BASE_DIR = os.getcwd()\n",
    "DATASETS_DIR = os.path.join(BASE_DIR, 'datasets')\n",
    "\n",
    "# ML Libraries removed ‚Äî CSV-only mode\n",
    "ML_AVAILABLE = False\n",
    "\n",
    "# Flask app\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class TrainedCSRModelService:\n",
    "\t\"\"\"Service that loads and serves your trained CSR model\"\"\"\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tself.model = None\n",
    "\t\tself.tokenizer = None\n",
    "\t\tself.denial_data = None\n",
    "\t\tself.member_data = None\n",
    "\t\tself.plan_data = None\n",
    "\n",
    "\t\t# Load your CSV data for context\n",
    "\t\tself._load_csv_data()\n",
    "\n",
    "\t\t# Model loading removed ‚Äî CSV-only mode\n",
    "\t\t# self._load_trained_model()\n",
    "\n",
    "\tdef _load_csv_data(self):\n",
    "\t\t\"\"\"Load your CSV data for direct lookups\"\"\"\n",
    "\t\ttry:\n",
    "\t\t\tself.denial_data = self._load_csv_with_encoding(os.path.join(DATASETS_DIR, 'denial_reason.csv'))\n",
    "\t\t\tself.member_data = self._load_csv_with_encoding(os.path.join(DATASETS_DIR, 'member_subscription.csv'))\n",
    "\t\t\tself.plan_data = self._load_csv_with_encoding(os.path.join(DATASETS_DIR, 'plan_coverage.csv'))\n",
    "\t\t\tlogger.info(f\"‚úÖ Loaded CSV data: {len(self.denial_data)} denials, {len(self.member_data)} members, {len(self.plan_data)} plans\")\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tlogger.error(f\"‚ùå Error loading CSV data: {e}\")\n",
    "\n",
    "\tdef _load_csv_with_encoding(self, file_path):\n",
    "\t\t\"\"\"Load CSV with multiple encoding attempts and handle formatting issues\"\"\"\n",
    "\t\tencodings = ['utf-8', 'utf-8-sig', 'latin-1', 'cp1252', 'iso-8859-1']\n",
    "\n",
    "\t\tfor encoding in encodings:\n",
    "\t\t\ttry:\n",
    "\t\t\t\t# Try different CSV parsing options\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\treturn pd.read_csv(file_path, encoding=encoding)\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\treturn pd.read_csv(file_path, encoding=encoding, sep=',', quotechar='\"', skipinitialspace=True)\n",
    "\t\t\texcept UnicodeDecodeError:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\texcept Exception:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\n",
    "\t\traise Exception(f\"Could not load {file_path} with any supported encoding\")\n",
    "\n",
    "\tdef _load_trained_model(self):\n",
    "\t\t\"\"\"Load your custom trained model\"\"\"\n",
    "\t\tif not ML_AVAILABLE:\n",
    "\t\t\tlogger.warning(\"‚ö†Ô∏è  ML libraries not available. Skipping model load.\")\n",
    "\t\t\treturn False\n",
    "\n",
    "\t\tmodel_paths = ['./csr_bot_model', './trained_csr_bot']\n",
    "\n",
    "\t\t# Try to load your custom trained model\n",
    "\t\tfor model_path in model_paths:\n",
    "\t\t\tif os.path.exists(model_path):\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tlogger.info(f\"ü§ñ Loading your custom trained model from {model_path}...\")\n",
    "\t\t\t\t\tself.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\t\t\t\t\tself.model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "\t\t\t\t\tlogger.info(\"‚úÖ Custom trained model loaded successfully!\")\n",
    "\t\t\t\t\treturn True\n",
    "\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\tlogger.warning(f\"‚ö†Ô∏è  Could not load custom model from {model_path}: {e}\")\n",
    "\n",
    "\t\t# Fallback: no model, rely on direct CSV + gentle fallbacks\n",
    "\t\tlogger.warning(\"‚ö†Ô∏è  No custom trained model found. Using direct CSV lookup only\")\n",
    "\t\treturn False\n",
    "\n",
    "\tdef process_query(self, user_query, query_type=None):\n",
    "\t\t\"\"\"Process user query using CSV data only (no model)\"\"\"\n",
    "\t\ttry:\n",
    "\t\t\t# First try direct CSV lookup for exact matches\n",
    "\t\t\tdirect_response = self._direct_csv_lookup(user_query, query_type)\n",
    "\t\t\tif direct_response:\n",
    "\t\t\t\treturn {\n",
    "\t\t\t\t\t'success': True,\n",
    "\t\t\t\t\t'response': direct_response,\n",
    "\t\t\t\t\t'source': 'direct_csv_lookup',\n",
    "\t\t\t\t\t'confidence': 0.95\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t# Model path removed; using CSV-only and fallback responses\n",
    "\n",
    "\t\t\t# Fallback response\n",
    "\t\t\treturn {\n",
    "\t\t\t\t'success': True,\n",
    "\t\t\t\t'response': self._get_fallback_response(user_query),\n",
    "\t\t\t\t'source': 'fallback',\n",
    "\t\t\t\t'confidence': 0.5\n",
    "\t\t\t}\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tlogger.error(f\"‚ùå Error processing query: {e}\")\n",
    "\t\t\treturn {\n",
    "\t\t\t\t'success': False,\n",
    "\t\t\t\t'error': str(e),\n",
    "\t\t\t\t'response': 'I encountered an error processing your request. Please try again.'\n",
    "\t\t\t}\n",
    "\n",
    "\tdef _direct_csv_lookup(self, query, query_type=None):\n",
    "\t\t\"\"\"Direct lookup in your CSV data\"\"\"\n",
    "\t\tquery_lower = query.lower()\n",
    "\n",
    "\t\t# Denial code lookup\n",
    "\t\tif query_type == 'denial' or any(word in query_lower for word in ['denial', 'code', 'reject', 'denied']):\n",
    "\t\t\t# Extract potential codes from query using regex\n",
    "\t\t\t# Look for patterns like CO-45, PR96, 204, etc.\n",
    "\t\t\tcodes = re.findall(r'\\b([A-Za-z]{1,2})-?(\\d{1,3})\\b', query, flags=re.I)\n",
    "\n",
    "\t\t\t# Match against CSV\n",
    "\t\t\tfor uc, dc in codes:\n",
    "\t\t\t\tmatch = self.denial_data[\n",
    "\t\t\t\t\t(self.denial_data['user_code'].str.upper() == uc.upper()) &\n",
    "\t\t\t\t\t(self.denial_data['denial_code'].astype(str).str.upper() == str(dc).upper())\n",
    "\t\t\t\t]\n",
    "\t\t\t\tif not match.empty:\n",
    "\t\t\t\t\trow = match.iloc[0]\n",
    "\t\t\t\t\treturn {\n",
    "\t\t\t\t\t\t'type': 'denial_explanation',\n",
    "\t\t\t\t\t\t'user_code': str(row['user_code']),\n",
    "\t\t\t\t\t\t'denial_code': str(row['denial_code']),\n",
    "\t\t\t\t\t\t'description': str(row['description']),\n",
    "\t\t\t\t\t\t'suggested_action': str(row['suggested_action'])\n",
    "\t\t\t\t\t}\n",
    "\n",
    "\t\t\t# If numeric-only provided (e.g., \"45\")\n",
    "\t\t\tonly_nums = re.findall(r'\\b(\\d{1,3})\\b', query)\n",
    "\t\t\tfor num in only_nums:\n",
    "\t\t\t\tsubset = self.denial_data[self.denial_data['denial_code'].astype(str) == num]\n",
    "\t\t\t\tif len(subset) == 1:\n",
    "\t\t\t\t\trow = subset.iloc[0]\n",
    "\t\t\t\t\treturn {\n",
    "\t\t\t\t\t\t'type': 'denial_explanation',\n",
    "\t\t\t\t\t\t'user_code': str(row['user_code']),\n",
    "\t\t\t\t\t\t'denial_code': str(row['denial_code']),\n",
    "\t\t\t\t\t\t'description': str(row['description']),\n",
    "\t\t\t\t\t\t'suggested_action': str(row['suggested_action'])\n",
    "\t\t\t\t\t}\n",
    "\n",
    "\t\t# Member lookup / coverage lookup\n",
    "\t\tif query_type == 'member' or any(word in query_lower for word in ['member', 'patient', 'covered', 'coverage', 'plan']):\n",
    "\t\t\t# Try to extract member id like M12345\n",
    "\t\t\tmid = re.search(r'\\b[Mm]\\d+\\b', query)\n",
    "\t\t\tif mid:\n",
    "\t\t\t\tmember_id = mid.group(0).upper()\n",
    "\t\t\t\tmember_rows = self.member_data[self.member_data['member_id'].astype(str).str.upper() == member_id]\n",
    "\t\t\t\tif not member_rows.empty:\n",
    "\t\t\t\t\tmember = member_rows.iloc[0]\n",
    "\t\t\t\t\tplan_info = self.plan_data[self.plan_data['plan_id'] == member['plan_id']]\n",
    "\t\t\t\t\tplan_details = {}\n",
    "\t\t\t\t\tif not plan_info.empty:\n",
    "\t\t\t\t\t\tplan_row = plan_info.iloc[0]\n",
    "\t\t\t\t\t\tplan_details = {\n",
    "\t\t\t\t\t\t\t'coverage_type': str(plan_row.get('coverage_type', '')),\n",
    "\t\t\t\t\t\t\t'covered_services': str(plan_row.get('covered_services', '')),\n",
    "\t\t\t\t\t\t\t'copay': str(plan_row.get('copay', '')),\n",
    "\t\t\t\t\t\t\t'notes': str(plan_row.get('notes', ''))\n",
    "\t\t\t\t\t\t}\n",
    "\n",
    "\t\t\t\t\tcoverage_answer = self._analyze_coverage_question(query_lower, plan_info.iloc[0] if not plan_info.empty else {'covered_services': ''})\n",
    "\t\t\t\t\treturn {\n",
    "\t\t\t\t\t\t'type': 'member_coverage',\n",
    "\t\t\t\t\t\t'member_id': str(member.get('member_id', '')),\n",
    "\t\t\t\t\t\t'member_name': str(member.get('member_name', '')),\n",
    "\t\t\t\t\t\t'plan_id': str(member.get('plan_id', '')),\n",
    "\t\t\t\t\t\t'status': str(member.get('status', '')),\n",
    "\t\t\t\t\t\t'effective_date': str(member.get('effective_date', '')),\n",
    "\t\t\t\t\t\t'end_date': str(member.get('end_date', '')),\n",
    "\t\t\t\t\t\t'coverage_answer': coverage_answer,\n",
    "\t\t\t\t\t\t'plan_details': plan_details\n",
    "\t\t\t\t\t}\n",
    "\n",
    "\t\t\t# Try plan id in query\n",
    "\t\t\tfor _, plan in self.plan_data.iterrows():\n",
    "\t\t\t\tpid = str(plan['plan_id'])\n",
    "\t\t\t\tif pid.lower() in query_lower:\n",
    "\t\t\t\t\tcoverage_answer = self._analyze_coverage_question(query_lower, plan)\n",
    "\t\t\t\t\treturn {\n",
    "\t\t\t\t\t\t'type': 'plan_coverage',\n",
    "\t\t\t\t\t\t'plan_id': str(plan['plan_id']),\n",
    "\t\t\t\t\t\t'coverage_type': str(plan['coverage_type']),\n",
    "\t\t\t\t\t\t'covered_services': str(plan['covered_services']),\n",
    "\t\t\t\t\t\t'copay': str(plan['copay']),\n",
    "\t\t\t\t\t\t'notes': str(plan['notes']),\n",
    "\t\t\t\t\t\t'coverage_answer': coverage_answer\n",
    "\t\t\t\t\t}\n",
    "\n",
    "\t\treturn None\n",
    "\n",
    "\tdef _analyze_coverage_question(self, query_lower, plan_row):\n",
    "\t\t\"\"\"Generate exact coverage answers using smart logic\"\"\"\n",
    "\t\tservices = str(plan_row.get('covered_services', '')).lower()\n",
    "\n",
    "\t\t# Find asked service (e.g., \"is dental covered\")\n",
    "\t\tm = re.search(r'is\\s+([a-z\\s]+?)\\s+covered', query_lower, flags=re.I)\n",
    "\t\tif m:\n",
    "\t\t\tasked = m.group(1).strip().lower()\n",
    "\t\t\tif asked:\n",
    "\t\t\t\treturn f\"Yes, {asked} is covered.\" if asked in services else f\"No, {asked} is not covered.\"\n",
    "\n",
    "\t\t# Copay questions\n",
    "\t\tif any(word in query_lower for word in ['copay', 'cost', 'pay', 'charge', 'fee']):\n",
    "\t\t\treturn f\"Copay: {plan_row.get('copay', '')}\"\n",
    "\n",
    "\t\treturn f\"This plan covers: {plan_row.get('covered_services', '')}\"\n",
    "\n",
    "\tdef _generate_with_trained_model(self, user_query):\n",
    "\t\t\"\"\"Model removed ‚Äî CSV-only mode.\"\"\"\n",
    "\t\treturn {\n",
    "\t\t\t'type': 'generated_response',\n",
    "\t\t\t'response': 'Model disabled. Using CSV-based response only.'\n",
    "\t\t}\n",
    "\tdef _get_fallback_response(self, query):\n",
    "\t\t\"\"\"Fallback response when no specific match found\"\"\"\n",
    "\t\tquery_lower = query.lower()\n",
    "\n",
    "\t\tif any(word in query_lower for word in ['denial', 'code', 'reject']):\n",
    "\t\t\tavailable_codes = ', '.join([f\"{row['user_code']}{row['denial_code']}\" for _, row in self.denial_data.iterrows()])\n",
    "\t\t\treturn {\n",
    "\t\t\t\t'type': 'help_response',\n",
    "\t\t\t\t'message': f\"I can help explain denial codes. Available codes: {available_codes}. Please specify which code you'd like to know about.\"\n",
    "\t\t\t}\n",
    "\n",
    "\t\telif any(word in query_lower for word in ['member', 'patient']):\n",
    "\t\t\tavailable_members = ', '.join([f\"{row['member_name']} ({row['member_id']})\" for _, row in self.member_data.iterrows()])\n",
    "\t\t\treturn {\n",
    "\t\t\t\t'type': 'help_response',\n",
    "\t\t\t\t'message': f\"I can look up member information. Available members: {available_members}. Please specify which member you'd like to find.\"\n",
    "\t\t\t}\n",
    "\n",
    "\t\telif any(word in query_lower for word in ['plan', 'coverage']):\n",
    "\t\t\tavailable_plans = ', '.join([row['plan_id'] for _, row in self.plan_data.iterrows()])\n",
    "\t\t\treturn {\n",
    "\t\t\t\t'type': 'help_response',\n",
    "\t\t\t\t'message': f\"I can provide plan coverage information. Available plans: {available_plans}. Please specify which plan you're asking about.\"\n",
    "\t\t\t}\n",
    "\n",
    "\t\treturn {\n",
    "\t\t\t'type': 'general_help',\n",
    "\t\t\t'message': \"I can help you with denial code explanations, member information lookups, and plan coverage questions. Please ask me about any of these topics.\"\n",
    "\t\t}\n",
    "\n",
    "# Initialize the service\n",
    "try:\n",
    "\tmodel_service = TrainedCSRModelService()\n",
    "\tlogger.info(\"‚úÖ Trained CSR Model Service initialized successfully\")\n",
    "except Exception as e:\n",
    "\tlogger.error(f\"‚ùå Failed to initialize service: {e}\")\n",
    "\tmodel_service = None\n",
    "\n",
    "# Flask endpoints\n",
    "@app.route('/query', methods=['POST'])\n",
    "def process_query():\n",
    "\t\"\"\"Main query endpoint for Spring Boot backend to call\"\"\"\n",
    "\ttry:\n",
    "\t\tif not model_service:\n",
    "\t\t\treturn jsonify({'success': False, 'error': 'Model service is not available'}), 500\n",
    "\n",
    "\t\tdata = request.get_json()\n",
    "\t\tuser_query = (data or {}).get('query', '').strip()\n",
    "\t\tquery_type = (data or {}).get('type', None)  # Optional: 'denial', 'member', 'coverage'\n",
    "\n",
    "\t\tif not user_query:\n",
    "\t\t\treturn jsonify({'success': False, 'error': 'Please provide a query'}), 400\n",
    "\n",
    "\t\tlogger.info(f\"üîç Processing query: {user_query} (type: {query_type})\")\n",
    "\n",
    "\t\t# Process the query\n",
    "\t\tresult = model_service.process_query(user_query, query_type)\n",
    "\n",
    "\t\tlogger.info(f\"‚úÖ Response generated from {result.get('source', 'unknown')}\")\n",
    "\t\treturn jsonify(result)\n",
    "\n",
    "\texcept Exception as e:\n",
    "\t\tlogger.error(f\"Query endpoint error: {e}\")\n",
    "\t\treturn jsonify({'success': False, 'error': 'Failed to process query'}), 500\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "\t\"\"\"Health check endpoint\"\"\"\n",
    "\treturn jsonify({\n",
    "\t\t'status': 'healthy',\n",
    "\t\t'service': 'CSR CSV Lookup API',\n",
    "\t\t'timestamp': datetime.now().isoformat(),\n",
    "\t\t'model_loaded': bool(model_service and model_service.model),\n",
    "\t\t'data_loaded': bool(model_service and all([\n",
    "\t\t\tmodel_service.denial_data is not None,\n",
    "\t\t\tmodel_service.member_data is not None,\n",
    "\t\t\tmodel_service.plan_data is not None\n",
    "\t\t]))\n",
    "\t})\n",
    "\n",
    "@app.route('/train-status', methods=['GET'])\n",
    "def train_status():\n",
    "\t\"\"\"Check if model is trained or needs training\"\"\"\n",
    "\tmodel_paths = ['./csr_bot_model', './trained_csr_bot']\n",
    "\ttrained_model_exists = any(os.path.exists(path) for path in model_paths)\n",
    "\n",
    "\treturn jsonify({\n",
    "\t\t'trained_model_exists': False,\n",
    "\t\t'model_loaded': False,\n",
    "\t\t'csv_data_available': all([\n",
    "\t\t\tos.path.exists(os.path.join(DATASETS_DIR, 'denial_reason.csv')),\n",
    "\t\t\tos.path.exists(os.path.join(DATASETS_DIR, 'member_subscription.csv')),\n",
    "\t\t\tos.path.exists(os.path.join(DATASETS_DIR, 'plan_coverage.csv'))\n",
    "\t\t]),\n",
    "\t\t'recommendation': 'csv_only'\n",
    "\t})\n",
    "\n",
    "@app.route('/available-data', methods=['GET'])\n",
    "def available_data():\n",
    "\t\"\"\"Get summary of available data\"\"\"\n",
    "\tif not model_service:\n",
    "\t\treturn jsonify({'error': 'Service not available'}), 500\n",
    "\n",
    "\treturn jsonify({\n",
    "\t\t'denial_codes': [\n",
    "\t\t\t{\n",
    "\t\t\t\t'code': f\"{row['user_code']}{row['denial_code']}\",\n",
    "\t\t\t\t'description': row['description']\n",
    "\t\t\t}\n",
    "\t\t\tfor _, row in model_service.denial_data.iterrows()\n",
    "\t\t] if model_service.denial_data is not None else [],\n",
    "\t\t'members': [\n",
    "\t\t\t{\n",
    "\t\t\t\t'id': row['member_id'],\n",
    "\t\t\t\t'name': row['member_name'],\n",
    "\t\t\t\t'plan': row['plan_id']\n",
    "\t\t\t}\n",
    "\t\t\tfor _, row in model_service.member_data.iterrows()\n",
    "\t\t] if model_service.member_data is not None else [],\n",
    "\t\t'plans': [\n",
    "\t\t\t{\n",
    "\t\t\t\t'id': row['plan_id'],\n",
    "\t\t\t\t'type': row['coverage_type'],\n",
    "\t\t\t\t'services': row['covered_services']\n",
    "\t\t\t}\n",
    "\t\t\tfor _, row in model_service.plan_data.iterrows()\n",
    "\t\t] if model_service.plan_data is not None else []\n",
    "\t})\n",
    "\n",
    "# Start the API server in a background thread and keep the cell alive\n",
    "def run_api():\n",
    "\tprint(\"üöÄ Starting CSR CSV Lookup API on http://localhost:5004\")\n",
    "\tprint(\"üì° Endpoints:\")\n",
    "\tprint(\"   POST /query\")\n",
    "\tprint(\"   GET  /health\")\n",
    "\tprint(\"   GET  /train-status\")\n",
    "\tprint(\"   GET  /available-data\")\n",
    "\tapp.run(host='0.0.0.0', port=5004, debug=False, use_reloader=False)\n",
    "\n",
    "api_thread = threading.Thread(target=run_api, daemon=True)\n",
    "api_thread.start()\n",
    "\n",
    "print(\"üéâ API service started! Keep this cell running.\")\n",
    "print(\"Your Spring Boot backend can connect to: http://localhost:5004\")\n",
    "\n",
    "# No blocking loop in CSV-only mode\n",
    "time.sleep(2)\n",
    "print(\"‚úÖ API thread running (non-blocking).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
